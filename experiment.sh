# CUDA_VISIBLE_DEVICES=5 python evals/lm_harness_eval_7b.py --model mamba --model_args pretrained=/share/public_models/mamba-7b-rw --tasks wikitext,lambada_openai,piqa,winogrande,arc_easy,hellaswag --device cuda --batch_size 16 >> experiment.log
CUDA_VISIBLE_DEVICES=5 python evals/lm_harness_eval.py --model mamba --model_args pretrained=/share/public_models/mamba-2.8b --tasks wikitext,lambada_openai,piqa,winogrande,arc_easy,hellaswag --device cuda --batch_size 64 >> experiment.log
CUDA_VISIBLE_DEVICES=5 python evals/lm_harness_eval.py --model mamba --model_args pretrained=/share/public_models/mamba-1.4b --tasks wikitext,lambada_openai,piqa,winogrande,arc_easy,hellaswag --device cuda --batch_size 64 >> experiment.log
CUDA_VISIBLE_DEVICES=5 python evals/lm_harness_eval.py --model mamba --model_args pretrained=/share/public_models/mamba-790m --tasks wikitext,lambada_openai,piqa,winogrande,arc_easy,hellaswag --device cuda --batch_size 64 >> experiment.log
CUDA_VISIBLE_DEVICES=5 python evals/lm_harness_eval.py --model mamba --model_args pretrained=/share/public_models/mamba-370m --tasks wikitext,lambada_openai,piqa,winogrande,arc_easy,hellaswag --device cuda --batch_size 64 >> experiment.log
CUDA_VISIBLE_DEVICES=5 python evals/lm_harness_eval.py --model mamba --model_args pretrained=/share/public_models/mamba-130m --tasks wikitext,lambada_openai,piqa,winogrande,arc_easy,hellaswag --device cuda --batch_size 64 >> experiment.log

